@inproceedings{Verdoolaege10,
   author = {Verdoolaege, Sven},
   title = {isl: {A}n Integer Set Library for the Polyhedral Model},
   booktitle = {Mathematical Software (ICMS 2010)},
   year = {2010},
   pages={299--302},
   series={LNCS 4151},
   editor={Andres Iglesias and Nobuki Takayama},
   publisher = {Springer-Verlag},
}
@article{Baskaran:2009:CDS:1594835.1504209,
 author = {Baskaran, Muthu Manikandan and Vydyanathan, Nagavijayalakshmi and Bondhugula, Uday Kumar Reddy and Ramanujam, J. and Rountev, Atanas and Sadayappan, P.},
 title = {Compiler-assisted dynamic scheduling for effective parallelization of loop nests on multicore processors},
 journal = {SIGPLAN Not.},
 issue_date = {April 2009},
 volume = {44},
 number = {4},
 month = feb,
 year = {2009},
 issn = {0362-1340},
 pages = {219--228},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1594835.1504209},
 doi = {10.1145/1594835.1504209},
 acmid = {1504209},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {compile-time optimization, dynamic scheduling, run-time optimization},
 abstract = {Recent advances in polyhedral compilation technology have made it feasible to automatically transform affine sequential loop nests for tiled parallel execution on multi-core processors. However, for multi-statement input programs with statements of different dimensionalities, such as Cholesky or LU decomposition, the parallel tiled code generated by existing automatic parallelization approaches may suffer from significant load imbalance, resulting in poor scalability on multi-core systems. In this paper, we develop a completely automatic parallelization approach for transforming input affine sequential codes into efficient parallel codes that can be executed on a multi-core system in a load-balanced manner. In our approach, we employ a compile-time technique that enables dynamic extraction of inter-tile dependences at run-time, and dynamic scheduling of the parallel tiles on the processor cores for improved scalable execution. Our approach obviates the need for programmer intervention and re-writing of existing algorithms for efficient parallel execution on multi-cores. We demonstrate the usefulness of our approach through comparisons using linear algebra computations: LU and Cholesky decomposition.}
}

@InProceedings{Bas04b,
 author = {C\'{e}dric Bastoul},
 title = {Code Generation in the Polyhedral Model Is Easier Than You Think},
 booktitle = {PACT'13 IEEE International Conference on Parallel Architecture
              and Compilation Techniques},
 year =	2004,
 pages = {7--16},
 month = {September},
 address = {Juan-les-Pins, France},
 abstract = {Many advances in automatic parallelization and optimization have been achieved through the polyhedral model. It has been extensively shown that this computational model provides convenient abstractions to reason about and apply program transformations. Nevertheless, the complexity of code generation has long been a deterrent for using polyhedral representation in optimizing compilers. First, code generators have a hard time coping with generated code size and control overhead that may spoil theoretical benefits achieved by the transformations. Second, this step is usually time consuming, hampering the integration of the polyhedral framework in production compilers or feedback-directed, iterative optimization schemes. Moreover, current code generation algorithms only cover a restrictive set of possible transformation functions. This paper discusses a general transformation framework able to deal with non-unimodular, non-invertible, non-integral or even non-uniform functions. It presents several improvements to a state-of-the-art code generation algorithm. Two directions are explored: generated code size and code generator efficiency. Experimental evidence proves the ability of the improved method to handle real-life problems.}
}

@article{Quillere00,
 author = {Quiller\'{e}, Fabien and Rajopadhye, Sanjay and Wilde, Doran},
 title = {Generation of Efficient Nested Loops from Polyhedra},
 journal = {Int. J. Parallel Programming},
 volume = 28,
 number=5,
 month=oct,
 year = 2000,
 pages={469--498},
 abstract = {Automatic parallelization in the polyhedral model is based on affine transformations from an original computation domain (iteration space) to a target space-time domain, often with a different transformation for each variable. Code generation is an often ignored step in this process that has a significant impact on the quality of the final code. It involves making a trade-off between code size and control code simplification/optimization. Previous methods of doing code generation are based on loop splitting, however they have non-optimal behavior when working on parameterized programs. We present a general parameterized method for code generation based on dual representation of polyhedra. Our algorithm uses a simple recursion on the dimensions of the domains, and enables fine control over the tradeoff between code size and control overhead.}
}

