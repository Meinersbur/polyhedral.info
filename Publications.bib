@Comment{{
We try to keep the formatting in this bibtex file consistent. Please
try to follow the following style guide.

- Order: The entries of this file are ordered by year of appearance and
          than by the bibtex tags (newest entries at the top).
- Tags:  Use the style <firstauthor.lastname><year.lasttwodigits><incrementing-letter>.
	   E.g. [Feautrier92b]
- '{}': Use a single pair of braces and embrace individual words/letters
         that should always remain uppercase.
- Abbreviations: Do not abbreviate conferences and journal names.
- Abstracts: Include abstracts, if available.
- ACM style: For all remaining style issues, we to follow the style used by ACM (see e.g.
               Baskaran09)

!! The style rules are necessarily incomplete, if you would like to improve
   the style of this file, feel free to provide a patch that both extends
   the style guide and fixes the existing entries.
}}

@inproceedings{Verdoolaege10,
   author = {Verdoolaege, Sven},
   title = {isl: {A}n Integer Set Library for the Polyhedral Model},
   booktitle = {Mathematical Software (ICMS 2010)},
   year = {2010},
   pages={299--302},
   series={LNCS 4151},
   editor={Andres Iglesias and Nobuki Takayama},
   publisher = {Springer-Verlag},
}

@article{Baskaran09,
 author = {Baskaran, Muthu Manikandan and Vydyanathan, Nagavijayalakshmi and
	   Bondhugula, Uday Kumar Reddy and Ramanujam, J. and Rountev, Atanas
           and Sadayappan, P.},
 title = {Compiler-assisted dynamic scheduling for effective parallelization of
          loop nests on multicore processors},
 journal = {SIGPLAN Not.},
 issue_date = {April 2009},
 volume = {44},
 number = {4},
 month = feb,
 year = {2009},
 issn = {0362-1340},
 pages = {219--228},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1594835.1504209},
 doi = {10.1145/1594835.1504209},
 acmid = {1504209},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {compile-time optimization, dynamic scheduling, run-time
             optimization},
 abstract = {
  Recent advances in polyhedral compilation technology have made it feasible to
  automatically transform affine sequential loop nests for tiled parallel
  execution on multi-core processors. However, for multi-statement input
  programs with statements of different dimensionalities, such as Cholesky or
  LU decomposition, the parallel tiled code generated by existing automatic
  parallelization approaches may suffer from significant load imbalance,
  resulting in poor scalability on multi-core systems. In this paper, we develop
  a completely automatic parallelization approach for transforming input affine
  sequential codes into efficient parallel codes that can be executed on a
  multi-core system in a load-balanced manner. In our approach, we employ a
  compile-time technique that enables dynamic extraction of inter-tile
  dependences at run-time, and dynamic scheduling of the parallel tiles on the
  processor cores for improved scalable execution. Our approach obviates the
  need for programmer intervention and re-writing of existing algorithms for
  efficient parallel execution on multi-cores. We demonstrate the usefulness of
  our approach through comparisons using linear algebra computations: LU and
  Cholesky decomposition.
 }
}

@InProceedings{Bastoul04,
 author = {Bastoul, C\'{e}dric},
 title = {Code Generation in the Polyhedral Model Is Easier Than You Think},
 booktitle = {PACT'13 IEEE International Conference on Parallel Architecture
              and Compilation Techniques},
 year =	2004,
 pages = {7--16},
 month = {September},
 address = {Juan-les-Pins, France},
 abstract = {
  Many advances in automatic parallelization and optimization have been
  achieved through the polyhedral model. It has been extensively shown that this
  computational model provides convenient abstractions to reason about and apply
  program transformations. Nevertheless, the complexity of code generation has
  long been a deterrent for using polyhedral representation in optimizing
  compilers. First, code generators have a hard time coping with generated code
  size and control overhead that may spoil theoretical benefits achieved by the
  transformations. Second, this step is usually time consuming, hampering the
  integration of the polyhedral framework in production compilers or
  feedback-directed, iterative optimization schemes. Moreover, current code
  generation algorithms only cover a restrictive set of possible transformation
  functions. This paper discusses a general transformation framework able to
  deal with non-unimodular, non-invertible, non-integral or even non-uniform
  functions. It presents several improvements to a state-of-the-art code
  generation algorithm. Two directions are explored: generated code size and
  code generator efficiency. Experimental evidence proves the ability of the
  improved method to handle real-life problems.
 }
}

@article{Quillere00,
 author = {Quiller\'{e}, Fabien and Rajopadhye, Sanjay and Wilde, Doran},
 title = {Generation of Efficient Nested Loops from Polyhedra},
 journal = {International Journal of Parallel Programming},
 volume = 28,
 number=5,
 month=oct,
 year = 2000,
 pages={469--498},
 abstract = {
  Automatic parallelization in the polyhedral model is based on affine
  transformations from an original computation domain (iteration space) to a
  target space-time domain, often with a different transformation for each
  variable. Code generation is an often ignored step in this process that has a
  significant impact on the quality of the final code. It involves making a
  trade-off between code size and control code simplification/optimization.
  Previous methods of doing code generation are based on loop splitting,
  however they have non-optimal behavior when working on parameterized
  programs. We present a general parameterized method for code generation based
  on dual representation of polyhedra. Our algorithm uses a simple recursion on
  the dimensions of the domains, and enables fine control over the tradeoff
  between code size and control overhead.
 }
}

@article{Feautrier92b,
 author = {Feautrier, Paul},
 affiliation = {Laboratoire MASI Universit√© de Versailles St-Quentin 45 Avenue
                des Etats-Unis 78035 Versailles Cedex France},
 title = {Some efficient solutions to the affine scheduling problem. Part II.
          Multidimensional time},
 journal = {International Journal of Parallel Programming},
 publisher = {Springer Netherlands},
 issn = {0885-7458},
 keyword = {Informatique},
 pages = {389-420},
 volume = {21},
 issue = {6},
 url = {http://dx.doi.org/10.1007/BF01379404},
 note = {10.1007/BF01379404},
 year = {1992},
 abstract = {
  This paper extends the algorithms which were given in Part I to cases in which
  there is no affine schedule, i.e. to problems whose parallel complexity is
  polynomial but not linear. The natural generalization is to multidimensional
  schedules with lexicographic ordering as temporal succession. Multidimensional
  affine schedules, are, in a sense, equivalent to polynomial schedules, and are
  much easier to handle automatically. Furthermore, there is a strong connexion
  between multidimensional schedules and loop nests, which allows one to prove
  that a static control program always has a multidimensional schedule. Roughly,
  a larger dimension indicates less parallelism. In the algorithm which is
  presented here, this dimension is computed dynamically, and is just sufficient
  for scheduling the source program. The algorithm lends itself to a "divide and
  conquer" strategy. The paper gives some experimental evidence for the
  applicability, performances and limitations of the algorithm.
 }
}

@article{Feautrier92a,
 author = {Feautrier, Paul},
 title = {Some efficient solutions to the affine scheduling problem: Part I.
          One-dimensional time},
 journal = {International Journal of Parallel Programming},
 issue_date = {Oct. 1992},
 volume = {21},
 number = {5},
 month = oct,
 year = {1992},
 issn = {0885-7458},
 pages = {313--348},
 numpages = {36},
 url = {http://dx.doi.org/10.1007/BF01407835},
 doi = {10.1007/BF01407835},
 acmid = {171448},
 publisher = {Kluwer Academic Publishers},
 address = {Norwell, MA, USA},
 keywords = {automatic parallelization, automatic systolic array design,
             scheduling},
 abstract = {
  Programs and systems of recurrence equations may be represented as
  sets of actions which are to be executed subject to precedence constraints. In
  many cases, actions may be labelled by integral vectors in some iteration
  domain, and precedence constraints may be described by affine relations. A
  schedule for such a program is a function which allows one to estimate the
  intrinsic degree of parallelism of the program and to compile a parallel
  version for multiprocessor architectures or systolic arrays. This paper deals
  with the problem of finding closed form schedules as affine or piecewise
  affine functions of the iteration vector. An efficient algorithm which
  reduces the scheduling problem to a parametric linear program of small size,
  which can be readily solved by an efficient algorithm.
 }
}

